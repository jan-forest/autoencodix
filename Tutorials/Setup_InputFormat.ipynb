{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up AUTOENCODIX\n",
    "<img src=\"https://raw.githubusercontent.com/jan-forest/autoencodix/5dabc4a697cbba74d3f6144dc4b6d0fd6df2b624/images/autoencodix_logo.svg\" alt=\"AUTOENCODIX-Logo\" width=\"300\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the code and create environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on macOS\n",
      "Repository already exists, skipping clone...\n",
      "/Users/maximilianjoas/development/empty_auto/autoencodix\n",
      "Copying macOS Makefile...\n",
      "Copied successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maximilianjoas/.pyenv/versions/3.10.4/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# test that python is 3.10 or greater, if not exit with error and message\n",
      ">>> Python version is 3.10\n",
      ">>> Checking your python version\n",
      ">>> Python version formated is 3010000000\n",
      ">>> Minimum Python version formated is 3010000000\n",
      ">>> Python version is good\n",
      "python3 -m pip install virtualenv\n",
      "Collecting virtualenv\n",
      "  Downloading virtualenv-20.30.0-py3-none-any.whl (4.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock<4,>=3.12.2\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /Users/maximilianjoas/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from virtualenv) (4.3.7)\n",
      "Collecting distlib<1,>=0.3.7\n",
      "  Downloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: distlib, filelock, virtualenv\n",
      "Successfully installed distlib-0.3.9 filelock-3.18.0 virtualenv-20.30.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 25.1 is available.\n",
      "You should consider upgrading via the '/Users/maximilianjoas/.pyenv/versions/3.10.4/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mpython3 -m venv venv-gallia\n",
      ">>> New virtualenv created. Activate with:\n",
      "source venv-gallia/bin/activate\n"
     ]
    }
   ],
   "source": [
    "# Check if running on macOS and if the repo exists\n",
    "!if [[ $(uname) == \"Darwin\" ]]; then echo \"Running on macOS\"; IS_MACOS=true; else echo \"Not running on macOS\"; IS_MACOS=false; fi\n",
    "!if [ -d \"autoencodix\" ]; then echo \"Repository already exists, skipping clone...\"; else echo \"Cloning repository...\"; git clone https://github.com/jan-forest/autoencodix.git; fi\n",
    "\n",
    "# Change to the repo directory\n",
    "%cd autoencodix\n",
    "%pwd\n",
    "\n",
    "# Copy macOS Makefile if on macOS\n",
    "!if [[ $(uname) == \"Darwin\" ]]; then if [ -f \"Makefile_macos\" ]; then echo \"Copying macOS Makefile...\"; cp Makefile_macos Makefile; echo \"Copied successfully\"; else echo \"Warning: Makefile_macos not found\"; fi; else echo \"Not on macOS, keeping default Makefile\"; fi\n",
    "\n",
    "# Create environment\n",
    "!make create_environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 test_environment.py\n",
      ">>> Development environment passes all tests!\n",
      "# python3 -m pip install build\n",
      "# python3 -m build --sdist\n",
      "python3 -m pip install -e .\n",
      "Obtaining file:///Users/maximilianjoas/development/empty_auto/autoencodix\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: src\n",
      "  Running setup.py develop for src\n",
      "Successfully installed src-1.0.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 25.1 is available.\n",
      "You should consider upgrading via the '/Users/maximilianjoas/.pyenv/versions/3.10.4/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mpython3 -m pip install -r requirements.txt\n",
      "Collecting Pillow==10.4.0\n",
      "  Downloading pillow-10.4.0-cp310-cp310-macosx_11_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting PyYAML==6.0.1\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-macosx_11_0_arm64.whl (169 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.3/169.3 KB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting anndata==0.10.8\n",
      "  Downloading anndata-0.10.8-py3-none-any.whl (124 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.4/124.4 KB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting click==8.1.7\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kaleido==0.2.1\n",
      "  Downloading kaleido-0.2.1-py2.py3-none-macosx_11_0_arm64.whl (85.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.8/85.8 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0mm[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib==3.7.1\n",
      "  Downloading matplotlib-3.7.1-cp310-cp310-macosx_11_0_arm64.whl (7.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx==3.3\n",
      "  Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting numba==0.57.0\n",
      "  Downloading numba-0.57.0-cp310-cp310-macosx_11_0_arm64.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy==1.23.5\n",
      "  Downloading numpy-1.23.5-cp310-cp310-macosx_11_0_arm64.whl (13.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting opencv_python==4.10.0.84\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting optuna==3.6.1\n",
      "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pandas==2.2.2\n",
      "  Downloading pandas-2.2.2-cp310-cp310-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hCollecting parquet==1.3.1\n",
      "  Downloading parquet-1.3.1-py3-none-any.whl (24 kB)\n",
      "Collecting plotly==5.22.0\n",
      "  Downloading plotly-5.22.0-py3-none-any.whl (16.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow==16.1.0\n",
      "  Downloading pyarrow-16.1.0-cp310-cp310-macosx_11_0_arm64.whl (26.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.0/26.0 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting scanpy==1.10.2\n",
      "  Downloading scanpy-1.10.2-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit_learn==1.3.0\n",
      "  Downloading scikit_learn-1.3.0-cp310-cp310-macosx_12_0_arm64.whl (9.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn-extra==0.3.0\n",
      "  Downloading scikit-learn-extra-0.3.0.tar.gz (818 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 KB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting scikit_plot==0.3.7\n",
      "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
      "Collecting scipy==1.14.0\n",
      "  Downloading scipy-1.14.0-cp310-cp310-macosx_14_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting seaborn==0.13.2\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 KB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard==2.17.0\n",
      "  Downloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch==2.3.1\n",
      "  Downloading torch-2.3.1-cp310-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting torcheval==0.0.7\n",
      "  Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 KB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchinfo==1.8.0\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Collecting torchvision==0.18.1\n",
      "  Downloading torchvision-0.18.1-cp310-cp310-macosx_11_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting umap_learn==0.5.6\n",
      "  Downloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting natsort\n",
      "  Downloading natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Collecting array-api-compat!=1.5,>1.4\n",
      "  Downloading array_api_compat-1.11.2-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/maximilianjoas/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from anndata==0.10.8->-r requirements.txt (line 3)) (25.0)\n",
      "Collecting h5py>=3.1\n",
      "  Downloading h5py-3.13.0-cp310-cp310-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: exceptiongroup in /Users/maximilianjoas/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from anndata==0.10.8->-r requirements.txt (line 3)) (1.2.2)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-macosx_11_0_arm64.whl (65 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.4/65.4 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.57.0-cp310-cp310-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /Users/maximilianjoas/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-macosx_11_0_arm64.whl (253 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.4/253.4 KB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 KB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting llvmlite<0.41,>=0.40.0dev0\n",
      "  Downloading llvmlite-0.40.1-cp310-cp310-macosx_11_0_arm64.whl (28.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.1/28.1 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting alembic>=1.5.0\n",
      "  Downloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 KB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sqlalchemy>=1.3.0\n",
      "  Downloading sqlalchemy-2.0.40-cp310-cp310-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting colorlog\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 KB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 KB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting thriftpy2\n",
      "  Downloading thriftpy2-0.5.2.tar.gz (782 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.3/782.3 KB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h\u001b[33m  WARNING: Missing build requirements in pyproject.toml for thriftpy2 from https://files.pythonhosted.org/packages/f8/3a/d983b26df17583a3cc865a9e1737bb8faacfa1e16e3ed17353ef48847e6b/thriftpy2-0.5.2.tar.gz#sha256=cefcb2f6f8b12c00054c6f942dd2323a53b48b8b6862312d03b677dcf0d4a6da (from parquet==1.3.1->-r requirements.txt (line 13)).\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The project does not specify a build backend, and pip cannot fall back to setuptools without 'wheel'.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tenacity>=6.2.0\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Collecting legacy-api-wrap>=1.4\n",
      "  Downloading legacy_api_wrap-1.4.1-py3-none-any.whl (10.0 kB)\n",
      "Collecting patsy\n",
      "  Downloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.9/232.9 KB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 KB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting statsmodels>=0.13\n",
      "  Downloading statsmodels-0.14.4-cp310-cp310-macosx_11_0_arm64.whl (9.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting session-info\n",
      "  Downloading session_info-1.0.1-py3-none-any.whl (9.1 kB)\n",
      "Collecting pynndescent>=0.5\n",
      "  Downloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: six>1.9 in /Users/maximilianjoas/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorboard==2.17.0->-r requirements.txt (line 22)) (1.17.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/maximilianjoas/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorboard==2.17.0->-r requirements.txt (line 22)) (58.1.0)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 KB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.71.0-cp310-cp310-macosx_12_0_universal2.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.2/106.2 KB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting protobuf!=4.24.0,<5.0.0,>=3.19.6\n",
      "  Downloading protobuf-4.25.7-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 KB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=0.4\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /Users/maximilianjoas/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from torch==2.3.1->-r requirements.txt (line 23)) (4.13.2)\n",
      "Requirement already satisfied: filelock in /Users/maximilianjoas/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from torch==2.3.1->-r requirements.txt (line 23)) (3.18.0)\n",
      "Collecting jinja2\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 KB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 KB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Mako\n",
      "  Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-macosx_11_0_arm64.whl (12 kB)\n",
      "Collecting stdlib_list\n",
      "  Downloading stdlib_list-0.11.1-py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Cython>=3.0.10\n",
      "  Using cached Cython-3.0.12-py2.py3-none-any.whl (1.2 MB)\n",
      "Collecting ply<4.0,>=3.4\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 KB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: scikit-learn-extra, thriftpy2\n",
      "  Building wheel for scikit-learn-extra (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for scikit-learn-extra: filename=scikit_learn_extra-0.3.0-cp310-cp310-macosx_14_0_arm64.whl size=417665 sha256=d0684f096f5cda9cc561b61b0befaf283aa43c908cd5ef74bc3705ddf9a5b0da\n",
      "  Stored in directory: /Users/maximilianjoas/Library/Caches/pip/wheels/60/e1/7f/881b5af199acf453d55d49d38e227d291fe5b562099ac29a68\n",
      "  Building wheel for thriftpy2 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for thriftpy2: filename=thriftpy2-0.5.2-cp310-cp310-macosx_14_0_arm64.whl size=797439 sha256=bdbe944fa278337c1efae691aa95deb8fed17ad85c14a70fdd3ff2093e79989c\n",
      "  Stored in directory: /Users/maximilianjoas/Library/Caches/pip/wheels/90/28/5f/279788e86e2eaccb3edc73bde9c815a9527602739a56344ff7\n",
      "Successfully built scikit-learn-extra thriftpy2\n",
      "Installing collected packages: pytz, ply, mpmath, kaleido, tzdata, tqdm, torchinfo, torcheval, threadpoolctl, tensorboard-data-server, tenacity, sympy, stdlib_list, sqlalchemy, PyYAML, pyparsing, protobuf, Pillow, numpy, networkx, natsort, MarkupSafe, markdown, llvmlite, legacy-api-wrap, kiwisolver, joblib, grpcio, fsspec, fonttools, Cython, cycler, colorlog, click, array-api-compat, absl-py, werkzeug, thriftpy2, session-info, scipy, pyarrow, plotly, patsy, pandas, opencv_python, numba, Mako, jinja2, h5py, contourpy, torch, tensorboard, statsmodels, scikit_learn, parquet, matplotlib, anndata, alembic, torchvision, seaborn, scikit_plot, scikit-learn-extra, pynndescent, optuna, umap_learn, scanpy\n",
      "Successfully installed Cython-3.0.12 Mako-1.3.10 MarkupSafe-3.0.2 Pillow-10.4.0 PyYAML-6.0.1 absl-py-2.2.2 alembic-1.15.2 anndata-0.10.8 array-api-compat-1.11.2 click-8.1.7 colorlog-6.9.0 contourpy-1.3.2 cycler-0.12.1 fonttools-4.57.0 fsspec-2025.3.2 grpcio-1.71.0 h5py-3.13.0 jinja2-3.1.6 joblib-1.4.2 kaleido-0.2.1 kiwisolver-1.4.8 legacy-api-wrap-1.4.1 llvmlite-0.40.1 markdown-3.8 matplotlib-3.7.1 mpmath-1.3.0 natsort-8.4.0 networkx-3.3 numba-0.57.0 numpy-1.23.5 opencv_python-4.10.0.84 optuna-3.6.1 pandas-2.2.2 parquet-1.3.1 patsy-1.0.1 plotly-5.22.0 ply-3.11 protobuf-4.25.7 pyarrow-16.1.0 pynndescent-0.5.13 pyparsing-3.2.3 pytz-2025.2 scanpy-1.10.2 scikit-learn-extra-0.3.0 scikit_learn-1.3.0 scikit_plot-0.3.7 scipy-1.14.0 seaborn-0.13.2 session-info-1.0.1 sqlalchemy-2.0.40 statsmodels-0.14.4 stdlib_list-0.11.1 sympy-1.14.0 tenacity-9.1.2 tensorboard-2.17.0 tensorboard-data-server-0.7.2 threadpoolctl-3.6.0 thriftpy2-0.5.2 torch-2.3.1 torcheval-0.0.7 torchinfo-1.8.0 torchvision-0.18.1 tqdm-4.67.1 tzdata-2025.2 umap_learn-0.5.6 werkzeug-3.1.3\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 25.1 is available.\n",
      "You should consider upgrading via the '/Users/maximilianjoas/.pyenv/versions/3.10.4/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mtouch src/utils/__init__.py\n",
      "touch src/data/__init__.py\n",
      "touch src/features/__init__.py\n",
      "touch src/models/__init__.py\n",
      "touch src/models/tuning/__init__.py\n",
      "touch src/visualization/__init__.py\n"
     ]
    }
   ],
   "source": [
    "!source venv-gallia/bin\n",
    "!make requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic usage of AUTOENCODIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data and supported format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Get your input data in the shape samples x features\n",
    "Each data modality should be provided as a data matrix with the shape samples x features with index names and column headers\n",
    "\n",
    "The data can be provided as text files (csv, tsv, txt) or as parquet-files\n",
    "\n",
    "Let's have a look at an example:\n",
    "- Combine five cancer subtypes from TCGA\n",
    "- prepare two data modalities: gene expression (RNA) and methylation data (METH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-02 12:40:58--  https://cbioportal-datahub.s3.amazonaws.com/brca_tcga_pan_can_atlas_2018.tar.gz\n",
      "Resolving cbioportal-datahub.s3.amazonaws.com (cbioportal-datahub.s3.amazonaws.com)... 3.5.12.86, 52.216.147.11, 52.216.42.225, ...\n",
      "Connecting to cbioportal-datahub.s3.amazonaws.com (cbioportal-datahub.s3.amazonaws.com)|3.5.12.86|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 491659217 (469M) [application/x-tar]\n",
      "Saving to: ‘brca_tcga_pan_can_atlas_2018.tar.gz’\n",
      "\n",
      "brca_tcga_pan_can_a 100%[===================>] 468.88M  3.44MB/s    in 1m 50s  \n",
      "\n",
      "2025-05-02 12:42:49 (4.28 MB/s) - ‘brca_tcga_pan_can_atlas_2018.tar.gz’ saved [491659217/491659217]\n",
      "\n",
      "--2025-05-02 12:42:51--  https://cbioportal-datahub.s3.amazonaws.com/luad_tcga_pan_can_atlas_2018.tar.gz\n",
      "Resolving cbioportal-datahub.s3.amazonaws.com (cbioportal-datahub.s3.amazonaws.com)... 3.5.28.241, 52.217.204.49, 16.15.184.118, ...\n",
      "Connecting to cbioportal-datahub.s3.amazonaws.com (cbioportal-datahub.s3.amazonaws.com)|3.5.28.241|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 285494295 (272M) [application/x-tar]\n",
      "Saving to: ‘luad_tcga_pan_can_atlas_2018.tar.gz’\n",
      "\n",
      "luad_tcga_pan_can_a 100%[===================>] 272.27M  6.76MB/s    in 43s     \n",
      "\n",
      "2025-05-02 12:43:35 (6.32 MB/s) - ‘luad_tcga_pan_can_atlas_2018.tar.gz’ saved [285494295/285494295]\n",
      "\n",
      "--2025-05-02 12:43:36--  https://cbioportal-datahub.s3.amazonaws.com/lusc_tcga_pan_can_atlas_2018.tar.gz\n",
      "Resolving cbioportal-datahub.s3.amazonaws.com (cbioportal-datahub.s3.amazonaws.com)... 52.216.217.129, 52.217.228.241, 3.5.30.97, ...\n",
      "Connecting to cbioportal-datahub.s3.amazonaws.com (cbioportal-datahub.s3.amazonaws.com)|52.216.217.129|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 256992991 (245M) [application/x-tar]\n",
      "Saving to: ‘lusc_tcga_pan_can_atlas_2018.tar.gz’\n",
      "\n",
      "lusc_tcga_pan_can_a 100%[===================>] 245.09M  6.86MB/s    in 42s     \n",
      "\n",
      "2025-05-02 12:44:19 (5.85 MB/s) - ‘lusc_tcga_pan_can_atlas_2018.tar.gz’ saved [256992991/256992991]\n",
      "\n",
      "--2025-05-02 12:44:20--  https://cbioportal-datahub.s3.amazonaws.com/ov_tcga_pan_can_atlas_2018.tar.gz\n",
      "Resolving cbioportal-datahub.s3.amazonaws.com (cbioportal-datahub.s3.amazonaws.com)... 54.231.193.1, 52.216.52.177, 52.216.250.116, ...\n",
      "Connecting to cbioportal-datahub.s3.amazonaws.com (cbioportal-datahub.s3.amazonaws.com)|54.231.193.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 208995543 (199M) [application/x-tar]\n",
      "Saving to: ‘ov_tcga_pan_can_atlas_2018.tar.gz’\n",
      "\n",
      "ov_tcga_pan_can_atl 100%[===================>] 199.31M  2.23MB/s    in 58s     \n",
      "\n",
      "2025-05-02 12:45:19 (3.43 MB/s) - ‘ov_tcga_pan_can_atlas_2018.tar.gz’ saved [208995543/208995543]\n",
      "\n",
      "--2025-05-02 12:45:20--  https://cbioportal-datahub.s3.amazonaws.com/coadread_tcga_pan_can_atlas_2018.tar.gz\n",
      "Resolving cbioportal-datahub.s3.amazonaws.com (cbioportal-datahub.s3.amazonaws.com)... 52.217.4.124, 3.5.30.113, 16.182.33.169, ...\n",
      "Connecting to cbioportal-datahub.s3.amazonaws.com (cbioportal-datahub.s3.amazonaws.com)|52.217.4.124|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 284181333 (271M) [application/x-tar]\n",
      "Saving to: ‘coadread_tcga_pan_can_atlas_2018.tar.gz’\n",
      "\n",
      "coadread_tcga_pan_c 100%[===================>] 271.02M  7.50MB/s    in 42s     \n",
      "\n",
      "2025-05-02 12:46:03 (6.47 MB/s) - ‘coadread_tcga_pan_can_atlas_2018.tar.gz’ saved [284181333/284181333]\n",
      "\n",
      "--2025-05-02 12:46:05--  https://cbioportal-datahub.s3.amazonaws.com/ucec_tcga_pan_can_atlas_2018.tar.gz\n",
      "Resolving cbioportal-datahub.s3.amazonaws.com (cbioportal-datahub.s3.amazonaws.com)... 54.231.224.201, 3.5.25.187, 3.5.16.151, ...\n",
      "Connecting to cbioportal-datahub.s3.amazonaws.com (cbioportal-datahub.s3.amazonaws.com)|54.231.224.201|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 414459220 (395M) [application/x-tar]\n",
      "Saving to: ‘ucec_tcga_pan_can_atlas_2018.tar.gz’\n",
      "\n",
      "ucec_tcga_pan_can_a  89%[================>   ] 352.63M  --.-KB/s    in 17m 8s  \n",
      "\n",
      "2025-05-02 13:03:13 (351 KB/s) - Read error at byte 369763941/414459220 (Operation timed out). Retrying.\n",
      "\n",
      "--2025-05-02 13:03:14--  (try: 2)  https://cbioportal-datahub.s3.amazonaws.com/ucec_tcga_pan_can_atlas_2018.tar.gz\n",
      "Connecting to cbioportal-datahub.s3.amazonaws.com (cbioportal-datahub.s3.amazonaws.com)|54.231.224.201|:443... connected.\n",
      "HTTP request sent, awaiting response... 206 Partial Content\n",
      "Length: 414459220 (395M), 44695279 (43M) remaining [application/x-tar]\n",
      "Saving to: ‘ucec_tcga_pan_can_atlas_2018.tar.gz’\n",
      "\n",
      "ucec_tcga_pan_can_a 100%[+++++++++++++++++==>] 395.26M  10.2MB/s    in 4.2s    \n",
      "\n",
      "2025-05-02 13:03:19 (10.2 MB/s) - ‘ucec_tcga_pan_can_atlas_2018.tar.gz’ saved [414459220/414459220]\n",
      "\n",
      "--2025-05-02 13:03:21--  https://cbioportal-datahub.s3.amazonaws.com/ucs_tcga_pan_can_atlas_2018.tar.gz\n",
      "Resolving cbioportal-datahub.s3.amazonaws.com (cbioportal-datahub.s3.amazonaws.com)... 54.231.172.145, 16.182.97.57, 3.5.21.110, ...\n",
      "Connecting to cbioportal-datahub.s3.amazonaws.com (cbioportal-datahub.s3.amazonaws.com)|54.231.172.145|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 24288596 (23M) [application/x-tar]\n",
      "Saving to: ‘ucs_tcga_pan_can_atlas_2018.tar.gz’\n",
      "\n",
      "ucs_tcga_pan_can_at 100%[===================>]  23.16M  4.06MB/s    in 6.2s    \n",
      "\n",
      "2025-05-02 13:03:28 (3.71 MB/s) - ‘ucs_tcga_pan_can_atlas_2018.tar.gz’ saved [24288596/24288596]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Download Breast Cancer (brca) from TCGA via cbioportal\n",
    "!wget https://cbioportal-datahub.s3.amazonaws.com/brca_tcga_pan_can_atlas_2018.tar.gz\n",
    "!tar -xzf brca_tcga_pan_can_atlas_2018.tar.gz\n",
    "\n",
    "## Download Non-Small Cell Lung Cancer (luad and lusc) from TCGA via cbioportal\n",
    "!wget https://cbioportal-datahub.s3.amazonaws.com/luad_tcga_pan_can_atlas_2018.tar.gz\n",
    "!tar -xzf luad_tcga_pan_can_atlas_2018.tar.gz\n",
    "!wget https://cbioportal-datahub.s3.amazonaws.com/lusc_tcga_pan_can_atlas_2018.tar.gz\n",
    "!tar -xzf lusc_tcga_pan_can_atlas_2018.tar.gz\n",
    "\n",
    "## Download Ovarian Epithelial Tumor (ov) from TCGA via cbioportal\n",
    "!wget https://cbioportal-datahub.s3.amazonaws.com/ov_tcga_pan_can_atlas_2018.tar.gz\n",
    "!tar -xzf ov_tcga_pan_can_atlas_2018.tar.gz\n",
    "\n",
    "## Download Colorectal Adenocarcinoma (coad and read) from TCGA via cbioportal\n",
    "!wget https://cbioportal-datahub.s3.amazonaws.com/coadread_tcga_pan_can_atlas_2018.tar.gz\n",
    "!tar -xzf coadread_tcga_pan_can_atlas_2018.tar.gz\n",
    "\n",
    "## Download Endometrial Carcinoma (ucec and ucs) from TCGA via cbioportal\n",
    "!wget https://cbioportal-datahub.s3.amazonaws.com/ucec_tcga_pan_can_atlas_2018.tar.gz\n",
    "!tar -xzf ucec_tcga_pan_can_atlas_2018.tar.gz\n",
    "!wget https://cbioportal-datahub.s3.amazonaws.com/ucs_tcga_pan_can_atlas_2018.tar.gz\n",
    "!tar -xzf ucs_tcga_pan_can_atlas_2018.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNASeq data\n",
      "Hugo_Symbol\tEntrez_Gene_Id\tTCGA-3C-AAAU-01\tTCGA-3C-AALI-01\tTCGA-3C-AALJ-01\n",
      "\t100130426\t0\t0\t0.9066\n",
      "\t100133144\t16.3644\t9.2659\t11.6228\n",
      "UBE2Q2P2\t100134869\t12.9316\t17.379\t9.2294\n",
      "HMGB1P1\t10357\t52.1503\t69.7553\t154.297\n",
      "\t10431\t408.076\t563.893\t1360.83\n",
      "\t136542\t0\t0\t0\n",
      "\t155060\t1187.01\t516.041\t592.022\n",
      "RNU12-2P\t26823\t0\t1.0875\t0\n",
      "SSX9P\t280660\t0\t0.5438\t0\n",
      "\n",
      "Methylation data\n",
      "ENTITY_STABLE_ID\tNAME\tDESCRIPTION\tTRANSCRIPT_ID\tTCGA-3C-AAAU-01\n",
      "cg00000292\tATP2A1\t1stExon\tNM_173201;NM_004320\t0.67848346283127\n",
      "cg00003994\tMEOX2\t1stExon\tNM_005924\t0.100005173216671\n",
      "cg00005847\tHOXD3\t5'UTR\tNM_006898\t0.875122134700595\n",
      "cg00007981\tPANX1\t1stExon\tNM_015368\t0.0286584491585683\n",
      "cg00008493\tKIAA1409;COX8C\tBody;5'UTR\tNM_020818;NM_182971\t0.954225470776835\n",
      "cg00008713\tIMPA2\tTSS1500\tNM_014214\t0.0849249456209205\n",
      "cg00009407\tTTC8\tTSS200\tNM_144596;NM_198310;NM_198309\t0.0311837978543924\n",
      "cg00011459\tPMM2;TMEM186\tBody;TSS1500\tNM_000303;NM_015421\t0.94043753639814\n",
      "cg00012199\tANG;RNASE4\tTSS1500\tNM_002937;NM_001145\t0.0473055017612671\n"
     ]
    }
   ],
   "source": [
    "## Assume we want to integrate RNAseq data and methylation data with Autoencodix\n",
    "## Let's have a look at the format\n",
    "!echo \"RNASeq data\"\n",
    "# !head ./stad_tcga_pan_can_atlas_2018/data_mrna_seq_v2_rsem.txt | cut -d$'\\t' -f1-5\n",
    "!head ./brca_tcga_pan_can_atlas_2018/data_mrna_seq_v2_rsem.txt | cut -d$'\\t' -f1-5\n",
    "!echo \"\" \n",
    "!echo \"Methylation data\"\n",
    "# !head ./stad_tcga_pan_can_atlas_2018/data_methylation_hm27_hm450_merged.txt | cut -d$'\\t' -f1-5 \n",
    "!head ./brca_tcga_pan_can_atlas_2018/data_methylation_hm27_hm450_merged.txt | cut -d$'\\t' -f1-5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For usage with AUTOENCODIX we need to adress the following format issues:\n",
    "\n",
    "- Standard format from cbioportal is flipped (features x samples)\n",
    "- Methylation data is not per gene (Entrez Gene ID), but per probe. This works with `varix` and other autoencoders, but for the ontology-based `ontix` it is better to aggregate methylation data per gene for better integration.  \n",
    "\n",
    "Let's reformat the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing RNASeq data...\n",
      "Shape of combined RNASeq data\n",
      "(3552, 20506)\n",
      "Processing Methylation data...\n",
      "Shape of combined Methylation data\n",
      "(3875, 11285)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## Function to format RNASeq data\n",
    "def format_rna_data(cancer_types):\n",
    "\tcombined_rna = []\n",
    "\tfor cancer_type in cancer_types:\n",
    "\t\tdf_rna = pd.read_csv(\n",
    "\t\t\tf\"./{cancer_type}_tcga_pan_can_atlas_2018/data_mrna_seq_v2_rsem.txt\",\n",
    "\t\t\tdelimiter=\"\\t\",\n",
    "\t\t\tindex_col=[\"Entrez_Gene_Id\"],\n",
    "\t\t\tdtype={\"Entrez_Gene_Id\": str},\n",
    "\t\t)  # We only need Entrez ID\n",
    "\t\tmap_hugo_entrez = df_rna[\"Hugo_Symbol\"]\n",
    "\t\tdf_rna = df_rna.drop(columns=[\"Hugo_Symbol\"], errors=\"ignore\")\n",
    "\t\tdf_rna = df_rna.loc[~df_rna.index.isnull(), :]  # Filter Genes without Entrez ID\n",
    "\t\tdf_rna = df_rna.T.dropna(axis=1)  # Swap rows and columns + drop features with NA values\n",
    "\t\tdf_rna = df_rna.loc[:, ~df_rna.columns.duplicated()]  # Remove duplicated features\n",
    "\t\tcombined_rna.append(df_rna)\n",
    "\n",
    "\tcombined_rna_df = pd.concat(combined_rna, axis=0)\n",
    "\tprint(f\"Shape of combined RNASeq data\")\n",
    "\tprint(combined_rna_df.shape)\n",
    "\n",
    "\tcombined_rna_df.to_parquet(\n",
    "\t\t\"combined_rnaseq_formatted.parquet\",\n",
    "\t\tindex=True,\n",
    "\t)\n",
    "\treturn map_hugo_entrez\n",
    "\n",
    "## Function to format methylation data\n",
    "def format_meth_data(cancer_types, map_hugo_entrez):\n",
    "\tcombined_meth = []\n",
    "\tfor cancer_type in cancer_types:\n",
    "\t\tdf_meth = pd.read_csv(\n",
    "\t\t\tf\"./{cancer_type}_tcga_pan_can_atlas_2018/data_methylation_hm27_hm450_merged.txt\",\n",
    "\t\t\tdelimiter=\"\\t\",\n",
    "\t\t\tindex_col=[\"ENTITY_STABLE_ID\"],\n",
    "\t\t\tdtype={\"ENTITY_STABLE_ID\": str},\n",
    "\t\t)\n",
    "\t\tdf_meth = df_meth.merge(\n",
    "\t\t\tmap_hugo_entrez.reset_index(),  # Get the Entrez ID from RNA data\n",
    "\t\t\tleft_on=\"NAME\",\n",
    "\t\t\tright_on=\"Hugo_Symbol\",\n",
    "\t\t)\n",
    "\t\tdf_meth = df_meth.drop(\n",
    "\t\t\tcolumns=[\"ENTITY_STABLE_ID\", \"NAME\", \"DESCRIPTION\", \"TRANSCRIPT_ID\"], errors=\"ignore\")  # Dropping not needed columns\n",
    "\t\tdf_meth = df_meth.groupby([\"Entrez_Gene_Id\"]).mean(numeric_only=True)  # Aggregate over multiple measurements per gene to match RNA data\n",
    "\n",
    "\t\tdf_meth = df_meth.loc[~df_meth.index.isnull(), :]  # Filter Genes without Entrez ID\n",
    "\t\tdf_meth = df_meth.T.dropna(axis=1)  # Swap rows and columns + drop features with NA values\n",
    "\t\tdf_meth = df_meth.loc[:, ~df_meth.columns.duplicated()]  # Remove duplicated features\n",
    "\t\tcombined_meth.append(df_meth)\n",
    "\n",
    "\tcombined_meth_df = pd.concat(combined_meth, axis=0)\n",
    "\tprint(f\"Shape of combined Methylation data\")\n",
    "\tprint(combined_meth_df.shape)\n",
    "\n",
    "\tcombined_meth_df.to_parquet(\n",
    "\t\t\"combined_meth_formatted.parquet\",\n",
    "\t\tindex=True,\n",
    "\t)\n",
    "\n",
    "\n",
    "# List of cancer subtypes\n",
    "cancer_types = [\"brca\", \"lusc\", \"luad\", \"ov\", \"coadread\", \"ucec\", \"ucs\"]\n",
    "\n",
    "# Format data for all cancer subtypes\n",
    "print(\"Processing RNASeq data...\")\n",
    "map_hugo_entrez = format_rna_data(cancer_types)\n",
    "print(\"Processing Methylation data...\")\n",
    "format_meth_data(cancer_types, map_hugo_entrez)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A file with clinical variables for annotation is also required to create nice figures\n",
    "\n",
    "Let's check the files from TCGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First file:\n",
      "#Patient Identifier\tSubtype\tTCGA PanCanAtlas Cancer Type Acronym\tOther Patient ID\tDiagnosis Age\n",
      "#Identifier to uniquely specify a patient.\tSubtype\tText field to hold cancer type acronym used by TCGA PanCanAtlas.\tLegacy DMP patient identifier (DMPnnnn)\tAge at which a condition or disease was first diagnosed.\n",
      "#STRING\tSTRING\tSTRING\tSTRING\tNUMBER\n",
      "#1\t1\t1\t1\t1\n",
      "PATIENT_ID\tSUBTYPE\tCANCER_TYPE_ACRONYM\tOTHER_PATIENT_ID\tAGE\n",
      "TCGA-3C-AAAU\tBRCA_LumA\tBRCA\t6E7D5EC6-A469-467C-B748-237353C23416\t55\n",
      "TCGA-3C-AALI\tBRCA_Her2\tBRCA\t55262FCB-1B01-4480-B322-36570430C917\t50\n",
      "TCGA-3C-AALJ\tBRCA_LumB\tBRCA\t427D0648-3F77-4FFC-B52C-89855426D647\t62\n",
      "TCGA-3C-AALK\tBRCA_LumA\tBRCA\tC31900A4-5DCD-4022-97AC-638E86E889E4\t52\n",
      "TCGA-4H-AAAK\tBRCA_LumA\tBRCA\t6623FC5E-00BE-4476-967A-CBD55F676EA6\t50\n",
      "\n",
      "Second file:\n",
      "#Patient Identifier\tSample Identifier\tOncotree Code\tCancer Type\tCancer Type Detailed\n",
      "#Identifier to uniquely specify a patient.\tA unique sample identifier.\tOncotree Code\tCancer Type\tCancer Type Detailed\n",
      "#STRING\tSTRING\tSTRING\tSTRING\tSTRING\n",
      "#1\t1\t1\t1\t1\n",
      "PATIENT_ID\tSAMPLE_ID\tONCOTREE_CODE\tCANCER_TYPE\tCANCER_TYPE_DETAILED\n",
      "TCGA-3C-AAAU\tTCGA-3C-AAAU-01\tILC\tBreast Cancer\tBreast Invasive Lobular Carcinoma\n",
      "TCGA-3C-AALI\tTCGA-3C-AALI-01\tIDC\tBreast Cancer\tBreast Invasive Ductal Carcinoma\n",
      "TCGA-3C-AALJ\tTCGA-3C-AALJ-01\tIDC\tBreast Cancer\tBreast Invasive Ductal Carcinoma\n",
      "TCGA-3C-AALK\tTCGA-3C-AALK-01\tIDC\tBreast Cancer\tBreast Invasive Ductal Carcinoma\n",
      "TCGA-4H-AAAK\tTCGA-4H-AAAK-01\tILC\tBreast Cancer\tBreast Invasive Lobular Carcinoma\n"
     ]
    }
   ],
   "source": [
    "!echo \"First file:\"\n",
    "!head ./brca_tcga_pan_can_atlas_2018/data_clinical_patient.txt | cut -d$'\\t' -f1-5\n",
    "## Information in two files\n",
    "!echo \"\"\n",
    "!echo \"Second file:\"\n",
    "!head ./brca_tcga_pan_can_atlas_2018/data_clinical_sample.txt | cut -d$'\\t' -f1-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape is correct for AUTOENCODIX (samples x features)\n",
    "\n",
    "But we need to remove pre-header rows and need to join the two files based on SAMPLE_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinical variables we can use later for visualization:\n",
      "Index(['ONCOTREE_CODE', 'CANCER_TYPE', 'CANCER_TYPE_DETAILED', 'TUMOR_TYPE',\n",
      "       'GRADE', 'TISSUE_PROSPECTIVE_COLLECTION_INDICATOR',\n",
      "       'TISSUE_RETROSPECTIVE_COLLECTION_INDICATOR', 'TISSUE_SOURCE_SITE_CODE',\n",
      "       'TUMOR_TISSUE_SITE', 'ANEUPLOIDY_SCORE', 'SAMPLE_TYPE',\n",
      "       'MSI_SCORE_MANTIS', 'MSI_SENSOR_SCORE', 'SOMATIC_STATUS',\n",
      "       'TMB_NONSYNONYMOUS', 'TISSUE_SOURCE_SITE', 'TBL_SCORE', 'SUBTYPE',\n",
      "       'CANCER_TYPE_ACRONYM', 'OTHER_PATIENT_ID', 'AGE', 'SEX',\n",
      "       'AJCC_PATHOLOGIC_TUMOR_STAGE', 'AJCC_STAGING_EDITION',\n",
      "       'DAYS_LAST_FOLLOWUP', 'DAYS_TO_BIRTH',\n",
      "       'DAYS_TO_INITIAL_PATHOLOGIC_DIAGNOSIS', 'ETHNICITY',\n",
      "       'FORM_COMPLETION_DATE', 'HISTORY_NEOADJUVANT_TRTYN', 'ICD_10',\n",
      "       'ICD_O_3_HISTOLOGY', 'ICD_O_3_SITE', 'INFORMED_CONSENT_VERIFIED',\n",
      "       'NEW_TUMOR_EVENT_AFTER_INITIAL_TREATMENT', 'PATH_M_STAGE',\n",
      "       'PATH_N_STAGE', 'PATH_T_STAGE', 'PERSON_NEOPLASM_CANCER_STATUS',\n",
      "       'PRIMARY_LYMPH_NODE_PRESENTATION_ASSESSMENT', 'PRIOR_DX', 'RACE',\n",
      "       'RADIATION_THERAPY', 'WEIGHT', 'IN_PANCANPATHWAYS_FREEZE', 'OS_STATUS',\n",
      "       'OS_MONTHS', 'DSS_STATUS', 'DSS_MONTHS', 'DFS_STATUS', 'DFS_MONTHS',\n",
      "       'PFS_STATUS', 'PFS_MONTHS', 'GENETIC_ANCESTRY_LABEL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "combined_clin = []\n",
    "\n",
    "for cancer_type in cancer_types:\n",
    "\tdf_clin_sample = pd.read_csv(\n",
    "\t\tf\"./{cancer_type}_tcga_pan_can_atlas_2018/data_clinical_sample.txt\",\n",
    "\t\tindex_col=[\"PATIENT_ID\"],\n",
    "\t\tskiprows=3,\n",
    "\t\theader=1,\n",
    "\t\tdelimiter=\"\\t\",\n",
    "\t\tdtype={\"GRADE\": str} # Fix inconsistent data types\n",
    "\t\t)\n",
    "\tdf_clin_patient = pd.read_csv(\n",
    "\t\tf\"./{cancer_type}_tcga_pan_can_atlas_2018/data_clinical_patient.txt\",\n",
    "\t\tindex_col=[\"PATIENT_ID\"],\n",
    "\t\tskiprows=3,\n",
    "\t\theader=1,\n",
    "\t\tdelimiter=\"\\t\",\n",
    "\t\tdtype={\"AJCC_PATHOLOGIC_TUMOR_STAGE\":str, \"AJCC_STAGING_EDITION\": str, \"PATH_N_STAGE\":str} # Fix inconsistent data types\n",
    "\t)\n",
    "\n",
    "\t# Clean the DAYS_LAST_FOLLOWUP column\n",
    "\tdf_clin_patient[\"DAYS_LAST_FOLLOWUP\"] = pd.to_numeric(\n",
    "\t\tdf_clin_patient[\"DAYS_LAST_FOLLOWUP\"], errors=\"coerce\"\n",
    "\t)\n",
    "\n",
    "\tdf_clin = df_clin_sample.merge(\n",
    "\t\tdf_clin_patient, left_on=\"PATIENT_ID\", right_on=\"PATIENT_ID\"\n",
    "\t)\n",
    "\tdf_clin = df_clin.set_index(\"SAMPLE_ID\")\n",
    "\n",
    "\tfor col in df_clin:\n",
    "\t\tdt = df_clin[col].dtype\n",
    "\t\tif dt is object or dt is str:\n",
    "\t\t\tdf_clin[col] = df_clin[col].fillna(\"unknown\")  # Fill missing information in annotation files\n",
    "\t\t\tdf_clin[col] = df_clin[col].astype(str)  # Ensure consistent string type\n",
    "\n",
    "\tcombined_clin.append(df_clin)\n",
    "\n",
    "# Combine all clinical data into a single DataFrame\n",
    "combined_clin_df = pd.concat(combined_clin, axis=0)\n",
    "\n",
    "print(\"Clinical variables we can use later for visualization:\")\n",
    "print(combined_clin_df.columns)\n",
    "\n",
    "# Save the combined clinical data to a parquet file\n",
    "combined_clin_df.to_parquet(\"./combined_clin_formatted.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy formatted data to root data directory\n",
    "The standard directory for your final input data is in `data/raw`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/raw/combined_clin_formatted.parquet\n",
      "../data/raw/combined_meth_formatted.parquet\n",
      "../data/raw/combined_rnaseq_formatted.parquet\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ../data/raw/\n",
    "!cp ./combined_*.parquet ../data/raw/\n",
    "!ls ../data/raw/combined*.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to train autoencoders!  \n",
    "To do this check the other tutorials `Basiccs_Autoencodix.ipynb` or `Advanced_Ontix.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
